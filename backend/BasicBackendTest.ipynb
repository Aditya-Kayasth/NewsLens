{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio  # Install if not installed\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY7Q4GH-Tx4C",
        "outputId": "f6ad9cf5-dbe4-409e-cf6c-190301f46182"
      },
      "id": "BY7Q4GH-Tx4C",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import json\n",
        "import spacy\n",
        "import torch\n",
        "from typing import List, Dict\n",
        "from transformers import pipeline\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# ‚úÖ API Configuration\n",
        "NEWS_API_KEY = \"pub_713126568809cbb479e396fcef2b6c9d38644\"\n",
        "NEWS_API_URL = \"https://newsdata.io/api/1/news\"\n",
        "\n",
        "# ‚úÖ Countries\n",
        "COUNTRIES = {\n",
        "    \"India\": \"in\", \"USA\": \"us\", \"UK\": \"gb\", \"Canada\": \"ca\", \"Australia\": \"au\",\n",
        "    \"Germany\": \"de\", \"France\": \"fr\", \"China\": \"cn\", \"Japan\": \"jp\"\n",
        "}\n",
        "\n",
        "# ‚úÖ NLP Initialization\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# ‚úÖ Fetch News Asynchronously\n",
        "class NewsFetcher:\n",
        "    async def fetch_articles(self, session: aiohttp.ClientSession, query: str, country: str) -> List[Dict]:\n",
        "        params = {\n",
        "            \"apikey\": NEWS_API_KEY,\n",
        "            \"q\": query,\n",
        "            \"country\": country.lower(),\n",
        "            \"language\": \"en\",\n",
        "            \"size\": 10\n",
        "        }\n",
        "        try:\n",
        "            async with session.get(NEWS_API_URL, params=params) as response:\n",
        "                if response.status == 200:\n",
        "                    data = await response.json()\n",
        "                    return data.get(\"results\", [])\n",
        "                logging.error(f\"Error {response.status}: {await response.text()}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Network error: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# ‚úÖ Process News Articles\n",
        "class ArticleProcessor:\n",
        "    def process_article(self, article: Dict) -> Dict:\n",
        "      description = article.get(\"description\")  # Get description without default first\n",
        "      if not description:  # Check for None or empty string\n",
        "          return None\n",
        "\n",
        "      return {\n",
        "          \"title\": article.get(\"title\", \"Untitled Article\"),\n",
        "          \"source\": article.get(\"source_id\", \"Unknown source\"),\n",
        "          \"description\": description,\n",
        "          \"url\": article.get(\"link\", \"#\"),\n",
        "          \"published_date\": article.get(\"pubDate\", \"\"),\n",
        "          \"analysis\": self.analyze_content(description)\n",
        "      }\n",
        "\n",
        "    def analyze_content(self, text: str) -> Dict:\n",
        "        doc = nlp(text)\n",
        "        return {\n",
        "            \"sentiment\": sentiment_analyzer.polarity_scores(text),\n",
        "            \"entities\": {ent.text: ent.label_ for ent in doc.ents},\n",
        "            \"keywords\": [chunk.text for chunk in doc.noun_chunks]\n",
        "        }\n",
        "\n",
        "# ‚úÖ Main Execution\n",
        "async def main():\n",
        "    # üîπ User Input for Topic & Country\n",
        "    topic = input(\"\\nüîé Enter a topic to search for news: \").strip()\n",
        "\n",
        "    print(\"\\nüåç **Select a Location:**\")\n",
        "    for i, (country, code) in enumerate(COUNTRIES.items(), start=1):\n",
        "        print(f\"{i}. {country}\")\n",
        "\n",
        "    location_index = input(\"\\nEnter location number: \").strip()\n",
        "    chosen_location = list(COUNTRIES.values())[int(location_index) - 1] if location_index.isdigit() else \"in\"\n",
        "\n",
        "    # üîπ Initialize Fetcher & Processor\n",
        "    fetcher = NewsFetcher()\n",
        "    processor = ArticleProcessor()\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        articles = await fetcher.fetch_articles(session, topic, chosen_location)\n",
        "\n",
        "    processed_articles = [processor.process_article(a) for a in articles if a]\n",
        "    results = [p for p in processed_articles if p is not None]\n",
        "\n",
        "    # üîπ Save Results to JSON\n",
        "    with open(\"news_analysis.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # üîπ Display Results\n",
        "    if results:\n",
        "        print(\"\\nüì∞ **Latest News Articles:**\\n\")\n",
        "        for i, article in enumerate(results, start=1):\n",
        "            print(f\"üîπ **{i}. {article['title']}**\")\n",
        "            print(f\"üìñ **Description:** {article['description']}\")\n",
        "            print(f\"üîó [Read More]({article['url']})\")\n",
        "            print(f\"üìÖ Published on: {article['published_date']}\")\n",
        "            print(f\"üìå **Sentiment Analysis:** {article['analysis']['sentiment']}\\n\")\n",
        "            print(\"-\" * 80)\n",
        "    else:\n",
        "        print(\"\\n‚ùå No news articles found.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "    loop = asyncio.get_event_loop()\n",
        "    loop.run_until_complete(main())  # ‚úÖ Run the async function properly\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNq4dKUVn6-D",
        "outputId": "91a5c2cd-c36b-4419-f0c6-df73954422f1"
      },
      "id": "oNq4dKUVn6-D",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîé Enter a topic to search for news: Union Budget\n",
            "\n",
            "üåç **Select a Location:**\n",
            "1. India\n",
            "2. USA\n",
            "3. UK\n",
            "4. Canada\n",
            "5. Australia\n",
            "6. Germany\n",
            "7. France\n",
            "8. China\n",
            "9. Japan\n",
            "\n",
            "Enter location number: 1\n",
            "\n",
            "üì∞ **Latest News Articles:**\n",
            "\n",
            "üîπ **1. Andhra Pradesh to Play Key Role in Viksit Bharat, Says Petroleum Minister Hardeep Singh Puri**\n",
            "üìñ **Description:** Andhra Pradesh is full of opportunities in the petroleum sector and will play a key role in India‚Äôs march towards the goal of Viksit Bharat, said Hardeep Singh Puri, Minister for Petroleum and Natur...\n",
            "üîó [Read More](http://www.en.etemaaddaily.com/world/national/andhra-pradesh-to-play-key-role-in-viksit-bharat-says-petroleum-minister-hardeep-singh-puri:170843)\n",
            "üìÖ Published on: 2025-02-22 05:21:49\n",
            "üìå **Sentiment Analysis:** {'neg': 0.0, 'neu': 0.865, 'pos': 0.135, 'compound': 0.6124}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ **2. Budget Proposals On Agriculture, Fiscal Consolidation Commitment Positive For Price Stability: RBI Policy Minutes**\n",
            "üìñ **Description:** Presenting the Union Budget, Finance Minister Nirmala Sitharaman on February 1 pegged the fiscal deficit target at 4.4% of GDP for the financial year 2025-26.The post Budget Proposals On Agriculture, Fiscal Consolidation Commitment Positive For Price Stability: RBI Policy Minutes appeared first on News24.\n",
            "üîó [Read More](https://news24online.com/business/budget-proposals-on-agriculture-fiscal-consolidation-commitment-positive-for-price-stability-rbi-policy-minutes/482040/)\n",
            "üìÖ Published on: 2025-02-22 05:01:38\n",
            "üìå **Sentiment Analysis:** {'neg': 0.054, 'neu': 0.822, 'pos': 0.124, 'compound': 0.5423}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ **3. Apple Intelligence will expand to more languages with iOS 18.4 in April: All you need to know**\n",
            "üìñ **Description:** Just days after unveiling the budget-friendly iPhone 16E, Apple has announced the release timeline for its upcoming software update, iOS 18.4. This update, set to arrive in April, will bring significant improvements, including the expansion of Apple Intelligence to more languages. Let‚Äôs take a closer look at what Apple has announced. Through a blogpost, Apple [...]\n",
            "üîó [Read More](https://www.digit.in/apple-intelligence-will-expand-to-more-languages-with-ios-18-4-in-april-all-you-need-to-know/)\n",
            "üìÖ Published on: 2025-02-22 03:55:52\n",
            "üìå **Sentiment Analysis:** {'neg': 0.0, 'neu': 0.88, 'pos': 0.12, 'compound': 0.7351}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ **4. Reform, Perform And Transform Cities To Build Viksit Bharat**\n",
            "üìñ **Description:** The city infrastructure is experiencing severe stress and needs to build resilience to brace for the impact of climate change.\n",
            "üîó [Read More](https://www.ndtvprofit.com/opinion/reform-perform-and-transform-cities-to-build-viksit-bharat)\n",
            "üìÖ Published on: 2025-02-22 03:55:19\n",
            "üìå **Sentiment Analysis:** {'neg': 0.231, 'neu': 0.769, 'pos': 0.0, 'compound': -0.6597}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üîπ **5. Investors will not face red tapes: Vijayan at summit**\n",
            "üìñ **Description:** Over 3,000 delegates participated in the summit organised by the state government in its bid to attract investments and business proposals from several sectors\n",
            "üîó [Read More](https://www.hindustantimes.com/india-news/investors-will-not-face-red-tapes-vijayan-at-summit-101740164257712.html)\n",
            "üìÖ Published on: 2025-02-22 02:20:00\n",
            "üìå **Sentiment Analysis:** {'neg': 0.0, 'neu': 0.902, 'pos': 0.098, 'compound': 0.3612}\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BYnBsGFWsTTD"
      },
      "id": "BYnBsGFWsTTD"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load JSON file\n",
        "with open(\"news_analysis.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    news_data = json.load(f)\n",
        "\n",
        "# Extract URLs\n",
        "urls = [entry[\"url\"] for entry in news_data]\n",
        "\n",
        "# Function to extract text from a webpage\n",
        "def extract_text_from_url(url):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        # Extract the main article text (modify if needed)\n",
        "        paragraphs = soup.find_all(\"p\")\n",
        "        text = \" \".join([para.get_text() for para in paragraphs])\n",
        "        return text[:2000]  # Limit to 2000 characters for summarization\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching article: {str(e)}\"\n",
        "\n",
        "# Load the first summarization model\n",
        "summarizer1 = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# First round of summarization\n",
        "first_summaries = []\n",
        "for url in urls:\n",
        "    article_text = extract_text_from_url(url)\n",
        "    if \"Error\" in article_text:\n",
        "        first_summaries.append(article_text)\n",
        "    else:\n",
        "        summary = summarizer1(article_text, do_sample=False)\n",
        "        first_summaries.append(summary[0][\"summary_text\"])\n",
        "\n",
        "# Load the second summarization model (same or different)\n",
        "summarizer2 = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Second round of summarization\n",
        "final_summary = summarizer2(\" \".join(first_summaries), max_length=300, min_length=100, do_sample=False)\n",
        "\n",
        "# Print final summary\n",
        "print(\"\\nFinal Summarized Output:\\n\")\n",
        "print(final_summary[0][\"summary_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItgjMx6srRgP",
        "outputId": "69496ece-7b8e-4f10-b91a-e5968e220d97"
      },
      "id": "ItgjMx6srRgP",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Your max_length is set to 142, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
            "Your max_length is set to 142, but your input_length is only 3. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Summarized Output:\n",
            "\n",
            "Budget 2025 prioritises non-inflationary growth through careful fiscal management. Government‚Äôs entire borrowing to be channelled exclusively into capital expenditure. Apple has announced the release timeline for its upcoming software update, iOS 18.4. This update, set to arrive in April, will bring significant improvements, including the expansion of Apple Intelligence to more languages. CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Please submit your best shots of the U.S. for next week.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import requests\n",
        "import time\n",
        "from transformers import pipeline\n",
        "\n",
        "# ‚úÖ News API Key & URL\n",
        "NEWS_API_KEY = \"pub_713126568809cbb479e396fcef2b6c9d38644\"\n",
        "NEWS_API_URL = \"https://newsdata.io/api/1/news\"\n",
        "\n",
        "# ‚úÖ Load Summarization Model (BART Large CNN)\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# ‚úÖ Categories & Locations\n",
        "CATEGORIES = [\"top\", \"politics\", \"business\", \"technology\", \"sports\", \"health\",\n",
        "              \"entertainment\", \"science\", \"environment\", \"food\", \"education\"]\n",
        "\n",
        "COUNTRIES = {\n",
        "    \"India\": \"in\", \"USA\": \"us\", \"UK\": \"gb\", \"Canada\": \"ca\", \"Australia\": \"au\",\n",
        "    \"Germany\": \"de\", \"France\": \"fr\", \"China\": \"cn\", \"Japan\": \"jp\"\n",
        "}\n",
        "\n",
        "# ‚úÖ Fetch news articles\n",
        "def fetch_news(category, country):\n",
        "    params = {\n",
        "        \"apikey\": NEWS_API_KEY,\n",
        "        \"category\": category.lower(),\n",
        "        \"country\": country.lower(),\n",
        "        \"language\": \"en\",\n",
        "        \"size\": 5  # Fetching 5 articles for citations\n",
        "    }\n",
        "    response = requests.get(NEWS_API_URL, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    if response.status_code == 200 and \"results\" in data:\n",
        "        return data[\"results\"][:5]  # Get only the top 5 articles\n",
        "    else:\n",
        "        print(f\"‚ùå API Error: {data.get('message', 'Unknown error')}\")\n",
        "        return []\n",
        "\n",
        "# ‚úÖ Get summary using BART\n",
        "def get_summary(text):\n",
        "    try:\n",
        "        summary = summarizer(text, max_length=150, min_length=50, do_sample=False)\n",
        "        return summary[0][\"summary_text\"]\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error summarizing: {e}\")\n",
        "        return \"No summary available.\"\n",
        "\n",
        "# ‚úÖ Display menu for category selection\n",
        "print(\"\\nüìå **Select a News Category:**\")\n",
        "for i, category in enumerate(CATEGORIES, start=1):\n",
        "    print(f\"{i}. {category.capitalize()}\")\n",
        "\n",
        "category_index = input(\"\\nEnter category number: \").strip()\n",
        "chosen_category = CATEGORIES[int(category_index) - 1] if category_index.isdigit() else \"top\"\n",
        "\n",
        "# ‚úÖ Display menu for location selection\n",
        "print(\"\\nüåç **Select a Location:**\")\n",
        "for i, (country, code) in enumerate(COUNTRIES.items(), start=1):\n",
        "    print(f\"{i}. {country}\")\n",
        "\n",
        "location_index = input(\"\\nEnter location number: \").strip()\n",
        "chosen_location = list(COUNTRIES.values())[int(location_index) - 1] if location_index.isdigit() else \"in\"\n",
        "\n",
        "# üî• Fetch and process news\n",
        "news_articles = fetch_news(chosen_category, chosen_location)\n",
        "citations = []\n",
        "summaries = []\n",
        "\n",
        "if news_articles:\n",
        "    for article in news_articles:\n",
        "        title = article.get(\"title\", \"No title available\")\n",
        "        description = article.get(\"description\", \"No content available\")\n",
        "        url = article.get(\"link\", \"No URL available\")\n",
        "\n",
        "        if description != \"No content available\":\n",
        "            summary = get_summary(description)\n",
        "            summaries.append(summary)\n",
        "            citations.append(f\"{title} - {url}\")\n",
        "            time.sleep(1)  # Avoid overwhelming the summarizer\n",
        "\n",
        "    # ‚úÖ Combine summaries into a coherent overview\n",
        "    final_summary = \" \".join(summaries)[:500] + \"...\"\n",
        "\n",
        "    # ‚úÖ Output\n",
        "    print(\"\\nüì∞ **Citations:**\")\n",
        "    for cite in citations:\n",
        "        print(f\"- {cite}\")\n",
        "\n",
        "    print(\"\\nüìñ **Summary of all perspectives:**\")\n",
        "    print(final_summary)\n",
        "else:\n",
        "    print(\"‚ùå No news articles found.\")"
      ],
      "metadata": {
        "id": "e5dxLR3ksPVx"
      },
      "id": "e5dxLR3ksPVx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ai9U27KS7IEY"
      },
      "id": "ai9U27KS7IEY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}